---
title: 01. RAG とは何ですか？
description: What's RAG?
icon: TicketPercent
---

このセクションでは、RAG（Retrieval-Augmented Generation）について学びます。
まずは、生成AIサービスで使われている大規模言語モデル（LLM）とその制約について理解し、RAG がどのようにその問題を解決するかを見ていきます。

---

## 生成AIと大規模言語モデル（LLM）

一般に生成AIと呼ばれるサービス（ChatGPT、Claude、Gemini、Perplexity、DeepSeekなど）は、**大規模言語モデル（LLM）** をベースにしています。
LLM は広範なデータで訓練されていますが、その訓練データにはいくつかの制約があります。

### LLM の制約

#### 1. **ドメイン知識の限界**

- LLM は特定の分野に関しては精度が低く、特に専門的な分野（医療、法律、技術的な内容など）では正確な回答が得られない場合があります

#### 2. **ハルシネーション（幻覚）**

- LLM は時々、事実無根の情報や誤った内容を生成することがあります。そのため「AI は誤った情報を平気で生成する」という表現が使われることもあります

#### 3. **データのカットオフ**

- LLM の訓練データにはカットオフ日（モデルが訓練されたデータの最終日）があり、それ以降の最新の情報には対応できません

---

## RAG とは？

**RAG** は、これらの問題を解決するためのアプローチです。
RAG は、**R**`etrieval-`**A**`ugmented` **G**`eneration` の略で、日本語では「検索拡張生成」と訳されます。

### RAG のメリット

RAGを使うことで、以下のような利点があります。

- 外部データベースや検索エンジンから関連情報を取得し、プロンプトに組み込むことで、専門性を向上させる
- 事実に基づいた正確な回答を生成し、ハルシネーションを軽減する
- 必要に応じて最新情報や動的なデータ更新を反映する

---

## RAGが機能する仕組み

### RAG なしのシンプルなチャットアプリ

RAG がない場合、ユーザーからの質問はそのまま LLM に渡され、LLM はそのまま応答を生成します。

### RAG を使用したチャットアプリ

RAG を使用すると、質問プロンプトから「関連するデータを取得する」ステップが追加されます。
具体的には、外部データベースから関連情報（検索結果など）を取得し、その情報を含めたプロンプトを LLM に渡します。
これにより、より信頼性の高い応答が得られます。

---

## RAG の実現方法：LangChain

RAG を効率的かつ柔軟に活用するために、**LangChain** というフレームワークがあります。
LangChain は、外部データベースとの統合や検索・生成プロセスの調整を簡素化し、RAG の実装をサポートします。

---

次のセクションで、LangChain の具体的な役割と特徴についてさらに詳しくみていきましょう。
