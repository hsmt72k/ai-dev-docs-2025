---
title: 01. What's RAG?
description: RAG とは何ですか？
icon: Rocket
---

一般に生成 AI と呼ばれる形で提供されている
ChatGPT、Claude、Gemini、Perplexity、DeepSeek などのサービスは、
その中身は大規模言語モデル（LLM: Large Language Models）である。

LLM は広範なデータで訓練されているものの、訓練データにはいくつかの制約がある。

代表的な制約には情報の偏りやカバレッジ不足、最新情報が含まれないことなどが挙げられる。

結果として、以下の３つの問題点が発生する。

１つめの問題点は、**ドメイン知識の限界**。

「ドメイン」とは特定の分野のこと。

LLM は極端な特定の分野については、何も知らない。

LLM は広範な知識を持っているが、専門的な分野に関して精度が低い場合がある。

そのため、特定分野で深い専門性が求められるタスク（例えば、医療や法律、技術的な内容など）では、
正確な回答が得られないケースが見受けられ、誤解を招くリスクがある。

２つめの問題点は、**ハルシネーション**（幻覚）。

LLM は時として完全に事実無根な情報や誤った内容を生成することがある。

そのため「AI は誤った情報を平気で生成する」という表現が使われることもある。

生成された回答が一見信頼できそうに見えても、実際には論理的な誤りや事実誤認が含まれているケースもある。

３つめの問題点は、**データのカットオフ**。

LLMの学習データにはカットオフ日（モデルが訓練されたデータの最終日）が存在する。

そのため、カットオフ日以降の情報がモデルには含まれておらず、最新のニュースや最近の出来事には対応できない。

**RAG** は、これら３つの問題を改善するための技術的なアプローチである。

RAG とは `Retrieval-Augmented Generation` の頭文字を取ったもの。

日本語では、「検索拡張生成」と訳される。

RAG のアプローチにより、以下の具体的な成果が得られる。

- 外部データベースや検索エンジンから関連情報を取得し、プロンプトに組み込むことで専門性を向上
- 事実に基づいた正確な回答を生成し、ハルシネーションを軽減
- 必要に応じて最新情報や動的なデータ更新を反映

では、シンプルな Chat アプリで RAG はどのように機能するのか？

RAG がない場合、質問は LLM に渡され、応答が返される。

一方、RAG では質問プロンプトから始まり、「関連するデータを取得する」ステップが加わる。

このステップでは外部データベースから関連情報（検索結果など）を取得し、それらを含むプロンプトが LLM に渡される。

その結果、より信頼性の高い応答が得られることになる。

RAG を実現するフレームワークの１つとして、LangChain が役立つ。

LangChain は、外部データベースとの統合や検索・生成プロセスの調整を簡素化し、RAG を効率的かつ柔軟に活用できるようにサポートする。

続いては、この LangChain の具体的な役割と特徴について、さらに詳しく説明する。
