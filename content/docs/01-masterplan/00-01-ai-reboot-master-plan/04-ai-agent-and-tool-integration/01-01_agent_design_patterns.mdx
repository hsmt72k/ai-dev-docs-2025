---
title: エージェント設計パターン
description: Agent Design Patterns
icon: Blend
---

import { Mermaid } from "@/components/mdx/mermaid";

## AI エージェントの思考戦略：ReAct、Chain of Thought、リフレクションで実現する高度な問題解決

### 🔑 エグゼクティブサマリー

本ドキュメントでは、大規模言語モデル（LLM）を活用した AI エージェントの主要な設計パターンについて解説します。ReAct、Chain of Thought、リフレクション手法の３つの基本パターンは、AI エージェントの推論能力と問題解決能力を大幅に向上させるアプローチです。これらの手法を理解し適切に実装することで、より高度な判断力と自律性を持つ AI エージェントシステムを構築できます。

### 📋 本ドキュメントについて

**想定読者**：
- AI エンジニア、機械学習エンジニア
- LLM を活用したアプリケーション開発者
- AI エージェントシステムの設計者・開発者
- 生成 AI の組み込みシステムに興味のある技術者

**対象システム規模**：
- 単一エージェントから複数エージェントの連携システム
- 推論と行動を組み合わせた問題解決型アプリケーション
- 自己改善機能を備えた AI システム

### 🧠 Chain of Thought：段階的思考による推論強化

Chain of Thought（CoT）は、AI エージェントが複雑な問題解決を行う際に、人間のように段階的に思考過程を展開するテクニックです。単純な入力から出力への変換ではなく、複数のステップで推論を積み重ねる方法です。

**主な特徴**：
- 問題解決を複数の論理的ステップに分解
- 各ステップでの中間的な思考を明示的に表現
- 複雑な推論チェーンを追跡可能な形で構築
- エラー発見や修正が容易になる透明性を確保

**実装方法**：
1. プロンプト設計：「一歩ずつ考えてみましょう」などの指示を含める
2. 思考過程の可視化：各ステップでの推論を明示的に出力
3. 最終結論に至るまでの論理的なパスを構築

**適用例**：
- 複雑な数学的問題解決
- 多段階の論理パズル
- 段階的な意思決定が必要なシナリオ
- デバッグが必要な推論タスク

<Mermaid chart={`
graph LR
    A[問題入力] --> B[ステップ1の思考]
    B --> C[ステップ2の思考]
    C --> D[ステップ3の思考]
    D --> E[最終解答]
    style A fill:#FFC3A0,stroke:#FF8C61,color:#000
    style B fill:#D0E6FA,stroke:#3E92CC,color:#000
    style C fill:#D0E6FA,stroke:#3E92CC,color:#000
    style D fill:#D0E6FA,stroke:#3E92CC,color:#000
    style E fill:#C3E6CB,stroke:#4CAF50,color:#000
`} />

*図1: Chain of Thought における段階的な思考プロセスの流れ*

### 🔄 ReAct：思考と行動の融合による問題解決

ReAct（Reasoning + Acting）は、推論（Reasoning）と行動（Acting）を交互に繰り返すことで、より高度な問題解決を実現する設計パターンです。AI エージェントが思考するだけでなく、環境と相互作用しながら情報を収集し、判断を更新していきます。

**主な特徴**：
- 思考と行動のサイクルを繰り返す動的な問題解決プロセス
- 外部ツールや API との連携による情報収集
- 中間結果に基づく戦略の修正と適応
- より複雑な環境での自律的な意思決定

**実装ステップ**：
1. 思考（Reasoning）：現状分析と次の行動計画を立てる
2. 行動（Acting）：外部ツールを使用して情報収集や操作を実行
3. 観察（Observation）：行動の結果を観察して新たな情報を得る
4. ステップ 1-3 を目標達成まで繰り返す

**適用シナリオ**：
- 情報検索と統合が必要なタスク
- 複数のツールを組み合わせた作業
- 動的な環境での意思決定
- 継続的なフィードバックが必要な問題解決

<Mermaid chart={`
graph TD
    A[問題入力] --> B["思考<br />(Reasoning)"]
    B --> C["行動<br />(Acting)"]
    C --> D["観察<br />(Observation)"]
    D --> B
    B -- "目標達成" --> E[最終解答]
    style A fill:#FFC3A0,stroke:#FF8C61,color:#000
    style B fill:#FFD700,stroke:#B8860B,color:#000
    style C fill:#90EE90,stroke:#006400,color:#000
    style D fill:#87CEFA,stroke:#0047AB,color:#000
    style E fill:#C3E6CB,stroke:#4CAF50,color:#000
`} />

*図2: ReAct パターンにおける思考・行動・観察のサイクル*

### 🔍 リフレクション手法：自己評価と改善の循環

リフレクション手法は、AI エージェントが自らの出力や思考プロセスを評価し、改善するメカニズムを提供します。エージェントが「メタ認知」を持ち、自己批判的な視点で自身のパフォーマンスを向上させる設計パターンです。

**主な特徴**：
- 自己評価による品質向上と誤り修正
- 複数の視点や基準からの出力レビュー
- 失敗からの学習と改善サイクルの確立
- より洗練された回答や解決策の生成

**実装アプローチ**：
1. 初期解答の生成：問題に対する第一段階の回答を作成
2. 自己評価：生成した回答の強みと弱みを分析
3. 改善点の特定：不足している情報や論理的な誤りを指摘
4. 修正と最適化：評価に基づいて回答を改善
5. 必要に応じてプロセスを繰り返す

**応用例**：
- コード生成と最適化
- 文書作成と編集プロセス
- 複雑な質問への回答精度向上
- 批判的思考を要する問題解決

<Mermaid chart={`
graph TD
    A[問題入力] --> B[初期解答生成]
    B --> C[自己評価]
    C --> D{改善が必要か?}
    D -- はい --> E[改善点特定]
    E --> F[解答修正]
    F --> C
    D -- いいえ --> G[最終解答]
    style A fill:#FFC3A0,stroke:#FF8C61,color:#000
    style B fill:#D0E6FA,stroke:#3E92CC,color:#000
    style C fill:#FFD700,stroke:#B8860B,color:#000
    style D fill:#87CEFA,stroke:#0047AB,color:#000
    style E fill:#FF6347,stroke:#8B0000,color:#000
    style F fill:#90EE90,stroke:#006400,color:#000
    style G fill:#C3E6CB,stroke:#4CAF50,color:#000
`} />

*図3: リフレクション手法における自己評価と改善のサイクル*

### 📊 設計パターン比較と選択ガイド

各設計パターンには固有の強みと適用シナリオがあります。以下の表は、パターン選択の判断材料となる比較です。

| 設計パターン | 強み | 適したタスク | 実装の複雑さ |
|------------|------|------------|------------|
| Chain of Thought | 透明性の高い推論過程<br />デバッグが容易 | 数学問題<br />論理パズル<br />段階的思考が必要な問題 | 低〜中 |
| ReAct | 環境との相互作用<br />動的な問題解決 | 情報検索<br />ツール連携<br />複数ステップのタスク | 中〜高 |
| リフレクション | 自己改善能力<br />出力品質の向上 | 品質重視のタスク<br />創造的作業<br />コード生成 | 中〜高 |

### 🔄 パターン組み合わせによる相乗効果

これらの設計パターンは相互に排他的ではなく、組み合わせることで更に強力な AI エージェントを構築できます。

**組み合わせ例**：
- **ReAct + リフレクション**：行動と思考のサイクルに自己評価を組み込み、より適応的な問題解決を実現
- **Chain of Thought + リフレクション**：段階的思考の各ステップで自己評価を行い、推論の品質を向上
- **全パターンの統合**：複雑な問題に対して段階的思考、外部ツール活用、自己評価を組み合わせた総合的アプローチ

<Mermaid chart={`
graph TD
    A[問題入力] --> B[CoT: 段階的思考]
    B --> C[ReAct: 行動実行]
    C --> D[観察]
    D --> E[リフレクション: 自己評価]
    E --> F{目標達成?}
    F -- いいえ --> B
    F -- はい --> G[最終解答]
    style A fill:#FFC3A0,stroke:#FF8C61,color:#000
    style B fill:#D0E6FA,stroke:#3E92CC,color:#000
    style C fill:#90EE90,stroke:#006400,color:#000
    style D fill:#87CEFA,stroke:#0047AB,color:#000
    style E fill:#FFD700,stroke:#B8860B,color:#000
    style F fill:#FF6347,stroke:#8B0000,color:#000
    style G fill:#C3E6CB,stroke:#4CAF50,color:#000
`} />

*図4: 3つの設計パターンを組み合わせた統合アプローチ*

### 💡 実装のベストプラクティス

エージェント設計パターンの効果的な実装には、以下のポイントを考慮することが重要です。

**プロンプトエンジニアリング**：
- 明確な指示と制約条件の設定
- 思考過程を引き出す質問形式の活用
- 段階的なステップの明示的な要求
- 自己評価を促す基準の提示

**システム設計**：
- モジュール化された構造によるパターンの分離と組み合わせ
- 外部ツールとの効率的な連携インターフェース
- 中間結果の保存と活用のメカニズム
- エラー処理と回復戦略の組み込み

**評価と最適化**：
- 複数のメトリクスによるパフォーマンス測定
- 人間のフィードバックを取り入れた継続的改善
- 様々なタスクに対する汎用性の検証
- 計算効率とレスポンス時間の最適化

### 📚 用語解説

| 用語 | 説明 |
|------|------|
| LLM | Large Language Model（大規模言語モデル）。GPT-4、Claude、Llama などの大量のテキストデータで訓練された言語処理モデル。 |
| プロンプト | AI モデルへの入力として与えられる指示や質問のテキスト。 |
| トークン | LLM が処理する言語の最小単位。単語や文字のかたまりで、モデルの処理容量はトークン数で計測される。 |
| エージェント | 特定の目標を達成するために自律的に行動できる AI システム。 |
| ファインチューニング | 特定のタスクや領域に対してモデルを再訓練し、パフォーマンスを向上させるプロセス。 |
| RAG | Retrieval-Augmented Generation。外部知識ベースから関連情報を取得し、モデルの出力を拡張する手法。 |
| ハルシネーション | AI モデルが事実に基づかない情報を生成する現象。 |
