---
title: インクリメンタル応答表示
description: Streaming Response Rendering
icon: ArrowRightToLine
---

import { Mermaid } from "@/components/mdx/mermaid";

## 生成 AI でリアルな対話感を生む： インクリメンタル応答表示の実装

### 🔑 エグゼクティブサマリー

本ドキュメントでは、生成 AI システムにおける「インクリメンタル応答表示」の実装方法について解説します。AI の応答をタイプしているように徐々に表示する「タイピング効果」と、サーバーからリアルタイムでデータを受け取りながら表示する「ストリーミング表示」の両手法について、実装アプローチや技術的考慮点を示します。これらの技術を活用することで、より自然で人間らしい UX を実現し、ユーザーエンゲージメントを向上させることができます。

### 想定読者と適用範囲

- **想定読者**: フロントエンド開発者、バックエンド開発者、UX デザイナー
- **前提知識**: JavaScript/TypeScript、React などのフロントエンドフレームワーク、基本的な API 設計の理解
- **適用システム規模**: 小規模〜大規模 Web アプリケーション、モバイルアプリケーション
- **技術スタック**: React、Next.js、Vue.js などのフロントエンドフレームワーク、Node.js、Python、Go などのバックエンド

### 🎯 インクリメンタル応答表示の目的と効果

インクリメンタル応答表示を実装する主な目的と効果は以下の通りです。

- ユーザーに対する心理的な待ち時間の軽減
- より自然な人間とのコミュニケーション感の演出
- AI 処理の進捗状況の可視化
- 長文回答における情報の段階的な提供
- ユーザーエンゲージメントの向上
- システムの応答性に対する体感の改善

### 🔧 タイピング効果の実装

タイピング効果とは、テキストがリアルタイムで入力されているように文字を順次表示する UI 手法です。

#### 実装アプローチ

タイピング効果を実装するための主なアプローチは以下の通りです。

1. **JavaScript による純粋な実装**
   ```javascript
   function typeWriter(text, element, speed = 50) {
     let i = 0;
     const timer = setInterval(() => {
       if (i < text.length) {
         element.innerHTML += text.charAt(i);
         i++;
       } else {
         clearInterval(timer);
       }
     }, speed);
   }
   ```

2. **React での実装例**
   ```jsx
   const TypewriterEffect = ({ text, speed = 50 }) => {
     const [displayText, setDisplayText] = useState('');

     useEffect(() => {
       let i = 0;
       const timer = setInterval(() => {
         if (i < text.length) {
           setDisplayText((prev) => prev + text.charAt(i));
           i++;
         } else {
           clearInterval(timer);
         }
       }, speed);

       return () => clearInterval(timer);
     }, [text, speed]);

     return <div>{displayText}</div>;
   };
   ```

3. **専用ライブラリの活用**
   - `react-type-animation`
   - `typewriter-effect`
   - `typeit`

#### 最適化とカスタマイズ

タイピング効果の最適化とカスタマイズについて以下のポイントを考慮してください。

- **表示速度の調整**: 文字の表示速度は読みやすさとリアルさのバランスを考慮（通常 30〜80ms が適切）
- **不規則な速度**: 自然さを増すために若干のランダム要素を追加
- **特殊文字の処理**: 絵文字や改行などの特殊文字に対する適切な処理
- **キャンセル機能**: ユーザーがタイピングをスキップできる機能の実装
- **音声効果の追加**: タイプ音を追加する場合の考慮点

### 🌊 ストリーミング表示の実装

ストリーミング表示は、サーバーから生成された応答をリアルタイムで受け取り表示するため、大規模言語モデル（LLM）からの応答を即座に表示できます。

#### サーバーサイド実装

サーバーサイドでのストリーミング実装には以下の技術が利用できます。

1. **Server-Sent Events (SSE)**
   ```javascript
   // Node.js Express での実装例
   app.get('/stream', (req, res) => {
     res.setHeader('Content-Type', 'text/event-stream');
     res.setHeader('Cache-Control', 'no-cache');
     res.setHeader('Connection', 'keep-alive');

     // AI モデルからの応答をストリーミングで送信
     const aiModel = new AIModel();
     aiModel.generateStream(req.query.prompt, (chunk) => {
       res.write(`data: ${JSON.stringify({ text: chunk })}\n\n`);
     }, () => {
       res.write(`data: ${JSON.stringify({ done: true })}\n\n`);
       res.end();
     });
   });
   ```

2. **WebSocket**
   ```javascript
   // Node.js での WebSocket 実装例
   const WebSocket = require('ws');
   const wss = new WebSocket.Server({ port: 8080 });

   wss.on('connection', (ws) => {
     ws.on('message', (message) => {
       const data = JSON.parse(message);
       const aiModel = new AIModel();

       aiModel.generateStream(data.prompt, (chunk) => {
         ws.send(JSON.stringify({ text: chunk }));
       }, () => {
         ws.send(JSON.stringify({ done: true }));
       });
     });
   });
   ```

3. **OpenAI API / Anthropic API などの LLM サービスのストリーミング対応**
   ```javascript
   // OpenAI API を使ったストリーミング (Node.js)
   async function streamCompletion(req, res) {
     const response = await openai.completions.create({
       model: "gpt-3.5-turbo",
       prompt: req.body.prompt,
       stream: true,
       max_tokens: 1000
     });

     for await (const chunk of response) {
       res.write(`data: ${JSON.stringify({ text: chunk.choices[0].text })}\n\n`);
     }

     res.write(`data: ${JSON.stringify({ done: true })}\n\n`);
     res.end();
   }
   ```

#### クライアントサイド実装

クライアントサイドでのストリーミング実装手法は以下の通りです。

1. **Server-Sent Events の受信**
   ```javascript
   const eventSource = new EventSource('/stream?prompt=質問内容');
   let responseText = '';

   eventSource.onmessage = (event) => {
     const data = JSON.parse(event.data);

     if (data.done) {
       eventSource.close();
       return;
     }

     responseText += data.text;
     document.getElementById('response').textContent = responseText;
   };
   ```

2. **WebSocket での受信**
   ```javascript
   const socket = new WebSocket('ws://localhost:8080');
   let responseText = '';

   socket.onopen = () => {
     socket.send(JSON.stringify({ prompt: '質問内容' }));
   };

   socket.onmessage = (event) => {
     const data = JSON.parse(event.data);

     if (data.done) {
       socket.close();
       return;
     }

     responseText += data.text;
     document.getElementById('response').textContent = responseText;
   };
   ```

3. **React での実装例**
   ```jsx
   const StreamingResponse = ({ prompt }) => {
     const [response, setResponse] = useState('');
     const [isLoading, setIsLoading] = useState(false);

     useEffect(() => {
       if (!prompt) return;

       setIsLoading(true);
       setResponse('');

       const eventSource = new EventSource(`/stream?prompt=${encodeURIComponent(prompt)}`);

       eventSource.onmessage = (event) => {
         const data = JSON.parse(event.data);

         if (data.done) {
           eventSource.close();
           setIsLoading(false);
           return;
         }

         setResponse((prev) => prev + data.text);
       };

       return () => eventSource.close();
     }, [prompt]);

     return (
       <div>
         {isLoading && <span className="cursor-blink">▋</span>}
         <div>{response}</div>
       </div>
     );
   };
   ```

<div className="max-w-48">
<Mermaid chart={`
graph TD
    A[クライアント] --> B[HTTP リクエスト]
    B --> C[サーバー]
    C --> D[AI モデル]
    D -->|生成開始| E[ストリーミングレスポンス]
    E -->|チャンク単位で送信| F[Server-Sent Events/WebSocket]
    F -->|受信次第表示| G[UI レンダリング]
    G --> H[ユーザー画面]
    style A fill:#90EE90,stroke:#006400,color:#000
    style C fill:#87CEFA,stroke:#0047AB,color:#000
    style D fill:#FFD700,stroke:#B8860B,color:#000
    style E fill:#FF6347,stroke:#8B0000,color:#000
    style H fill:#DDA0DD,stroke:#8B008B,color:#000
`} />
</div>

<div className="text-slate-400">
*図1: ストリーミング表示の基本アーキテクチャ*
</div>

### 🔍 技術的考慮点

インクリメンタル応答表示を実装する際の技術的考慮点は以下の通りです。

#### パフォーマンスの最適化

- **DOM 操作の最小化**: 頻繁な DOM 更新による性能低下を防ぐ
- **Virtual DOM の活用**: React や Vue.js などのフレームワークの利点を活かす
- **スロットリング**: 更新頻度の制御による CPU 負荷の軽減
- **メモリ管理**: 長時間のストリーミングでのメモリリーク対策

#### UX 向上のためのテクニック

- **カーソル表示**: タイピング中のカーソル（▋）の点滅表示
- **スクロール自動調整**: 長文の場合、最新の内容が表示されるよう自動スクロール
- **マークダウン/HTML レンダリング**: 受信しながらリッチテキストとして表示
- **操作インタラクション**: ユーザーが途中で回答を止めたり、保存したりできる機能
- **アクセシビリティ考慮**: スクリーンリーダー対応など

#### エラーハンドリング

- **接続断絶時の処理**: ネットワーク切断時の回復メカニズム
- **タイムアウト処理**: 長時間応答がない場合の対応
- **部分データの保存**: 接続が切れた場合でも取得済みデータを保持
- **再接続ロジック**: 自動的に接続を再試行するメカニズム

### 🛡️ 異なるフレームワークでの実装例

様々なフレームワークでの実装方法について以下に示します。

#### Next.js での実装

```jsx
// app/api/stream/route.js
export async function GET(request) {
  const { searchParams } = new URL(request.url);
  const prompt = searchParams.get('prompt');

  // ストリームレスポンスの設定
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      // AI モデルに接続してストリーミング
      const response = await fetch('https://api.ai-service.com/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ prompt, stream: true }),
      });

      const reader = response.body.getReader();

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = new TextDecoder().decode(value);
        controller.enqueue(encoder.encode(`data: ${chunk}\n\n`));
      }

      controller.enqueue(encoder.encode('data: [DONE]\n\n'));
      controller.close();
    }
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}

// app/chat/page.jsx (クライアント側)
'use client';

import { useState, useEffect, useRef } from 'react';

export default function ChatPage() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [streaming, setStreaming] = useState(false);
  const messagesEndRef = useRef(null);

  const sendMessage = async (e) => {
    e.preventDefault();
    if (!input.trim() || streaming) return;

    const userMessage = { role: 'user', content: input };
    setMessages(prev => [...prev, userMessage]);
    setInput('');

    // AI の応答用メッセージを追加
    const aiMessageIndex = messages.length;
    setMessages(prev => [...prev, { role: 'assistant', content: '' }]);
    setStreaming(true);

    const eventSource = new EventSource(`/api/stream?prompt=${encodeURIComponent(input)}`);

    eventSource.onmessage = (event) => {
      if (event.data === '[DONE]') {
        eventSource.close();
        setStreaming(false);
        return;
      }

      setMessages(prev => {
        const updated = [...prev];
        updated[aiMessageIndex].content += event.data;
        return updated;
      });
    };

    eventSource.onerror = () => {
      eventSource.close();
      setStreaming(false);
    };
  };

  // 自動スクロール
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="chat-container">
      <div className="messages">
        {messages.map((msg, i) => (
          <div key={i} className={`message ${msg.role}`}>
            {msg.content}
            {streaming && i === messages.length - 1 && (
              <span className="cursor-blink">▋</span>
            )}
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      <form onSubmit={sendMessage}>
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="メッセージを入力..."
          disabled={streaming}
        />
        <button type="submit" disabled={streaming || !input.trim()}>
          送信
        </button>
      </form>
    </div>
  );
}
```

#### Vue.js での実装

```vue
<!-- ChatComponent.vue -->
<template>
  <div class="chat-container">
    <div class="messages" ref="messagesContainer">
      <div
        v-for="(message, index) in messages"
        :key="index"
        :class="['message', message.role]"
      >
        {{ message.content }}
        <span v-if="streaming && index === messages.length - 1" class="cursor-blink">▋</span>
      </div>
    </div>

    <form @submit.prevent="sendMessage">
      <input
        v-model="input"
        placeholder="メッセージを入力..."
        :disabled="streaming"
      />
      <button type="submit" :disabled="streaming || !input.trim()">
        送信
      </button>
    </form>
  </div>
</template>

<script>
export default {
  data() {
    return {
      messages: [],
      input: '',
      streaming: false
    };
  },
  methods: {
    sendMessage() {
      if (!this.input.trim() || this.streaming) return;

      this.messages.push({ role: 'user', content: this.input });
      this.input = '';

      // AI 応答用のプレースホルダー
      this.messages.push({ role: 'assistant', content: '' });
      this.streaming = true;

      const eventSource = new EventSource(`/api/stream?prompt=${encodeURIComponent(this.input)}`);
      const aiMessageIndex = this.messages.length - 1;

      eventSource.onmessage = (event) => {
        if (event.data === '[DONE]') {
          eventSource.close();
          this.streaming = false;
          return;
        }

        this.messages[aiMessageIndex].content += event.data;
        this.$nextTick(() => this.scrollToBottom());
      };

      eventSource.onerror = () => {
        eventSource.close();
        this.streaming = false;
      };
    },
    scrollToBottom() {
      const container = this.$refs.messagesContainer;
      container.scrollTop = container.scrollHeight;
    }
  },
  updated() {
    this.scrollToBottom();
  }
};
</script>
```

### 💼 実際のユースケースと事例

インクリメンタル応答表示の実際のユースケースと事例は以下の通りです。

1. **ChatGPT / Claude**: OpenAI と Anthropic の対話 AI
2. **GitHub Copilot**: コード補完時の段階的な表示
3. **カスタマーサポートチャットボット**: 顧客対応での人間らしい応答表示
4. **教育プラットフォーム**: 学習時の説明を段階的に表示
5. **ライティング支援ツール**: 文章生成時のリアルタイムフィードバック

### 📝 まとめ

インクリメンタル応答表示は、AI システムとのインタラクションにおいて、より自然で人間らしい対話体験を提供します。タイピング効果とストリーミング表示の実装により、ユーザーのエンゲージメントを高め、待機時間の体感を減らすことができます。

実装に際しては、パフォーマンス最適化、UX の考慮、エラーハンドリングなどの技術的側面に注意を払いながら、ユーザーの利用コンテキストに合った適切な表示速度とインタラクションを設計することが重要です。

正しく実装されたインクリメンタル応答表示は、AI システムのユーザビリティを大幅に向上させ、より自然でシームレスな対話体験を実現します。

### 用語解説

| 用語 | 説明 |
|------|------|
| インクリメンタル応答表示 | テキストを一度に表示せず、少しずつ表示する UI 技術 |
| タイピング効果 | テキストが入力されているように文字を順次表示する効果 |
| ストリーミング表示 | サーバーから受信したデータを即座に表示する技術 |
| SSE (Server-Sent Events) | サーバーからクライアントへの単方向通信を実現する技術 |
| WebSocket | クライアントとサーバー間の双方向リアルタイム通信を可能にするプロトコル |
| LLM (Large Language Model) | GPT や Claude などの大規模言語モデル |
| Virtual DOM | React や Vue.js などで使用される仮想的な DOM 表現 |
| スロットリング | 処理の頻度を制限してシステム負荷を軽減する技術 |
