---
title: スケーリング戦略
description: Scaling Strategy
icon: Scaling
---

## スケーリング戦略：リクエスト増加に対応するオートスケーリング設計

### 🔑 生成 AI システムのスケーリング戦略まとめ

* **生成 AI はリソース消費が不均一**：トークン数・複雑さで GPU 使用量が大きく変動します。
* **スケーリング手法は主に 2 つ**：
   * **水平スケーリング（ノード追加）**：インスタンス数を増やし並列処理能力を強化
   * **垂直スケーリング（マシン強化）**：より高性能な GPU やメモリを搭載したマシンに置き換え
* **オートスケーリング導入は必須**：CPU/GPU 利用率・レスポンス遅延・リクエスト数を監視し、自動的にリソース調整します。
* **スケーリング方式の 2 大パターン**：
   * **API 連携型**：小規模向け、導入・保守が簡単で初期コストが低い
   * **セルフホスティング型**：大規模向け、自由度・コスト効率・セキュリティが高い
* **最新技術の活用が鍵**：vLLM、Triton、軽量 LLM でスループット＆コスト最適化が可能です。
* **実装前の分析が重要**：ピーク時のトラフィック・レイテンシ要件・GPU 使用状況を測定して最適設計しましょう。

### 生成 AI システムでのスケーリングの特徴

生成 AI（ChatGPT や Claude 等の LLM）を組み込んだシステムでは、従来のウェブアプリケーションとは異なるスケーリングの特徴があります。

- **非均一なリソース消費** - テキスト生成の長さや複雑さによって処理時間が大きく変動します。単純な質問と長文生成では必要な計算リソースが 10 倍以上異なることもあります。
- **高い GPU メモリ要件** - 大規模言語モデルは一般に大量の GPU メモリを必要とします。最新のモデルでは 1 インスタンスあたり 24〜80GB 以上の GPU メモリが必要になることもあります。
- **バースト型のトラフィックパターン** - 特定のイベントや時間帯に利用が集中しやすく、通常時の 3〜5 倍のトラフィックが突発的に発生することがあります。また、マーケティングキャンペーンやメディア露出後に急激なトラフィック増加が見られることも特徴です。

### オートスケーリングとは

オートスケーリングとは、トラフィックやリソース需要の変動に応じて、システムが自動的にコンピューティングリソースを増減させる技術です。
`Auto Scaling` は、需要の増加時にはリソースを追加し、需要の減少時にはリソースを削減することで、パフォーマンスを維持しながらコスト効率を最適化します。
効果的なオートスケーリングにより、手動介入なしでピーク時の需要に対応しつつ、非ピーク時のコスト削減が可能になります。

### スケーリングの種類

import { Mermaid } from "@/components/mdx/mermaid";

<Mermaid chart={`
graph TB
  A[スケーリング戦略] --> B[水平スケーリング]
  A --> C[垂直スケーリング]
  B --> D["インスタンス数を増加 <br> (スケールアウト)"]
  C --> E["リソース容量を増加 <br> (スケールアップ)"]
  D --> F["• 無制限にスケール可能<br>• 高可用性<br>• コスト効率"]
  E --> G["• アプリ変更が少ない<br>• DBに適している<br>• ハードウェア制限あり"]
`} />

#### 水平スケーリング（`Horizontal Scaling`）

インスタンスやノードの数を増減させる方法です。ウェブサーバー、ステートレスアプリケーション、マイクロサービスに適しています。

- **メリット**：
  - 理論上は無制限にスケールアウトが可能
  - 単一障害点がなく高可用性を実現
  - 中小規模のインスタンスを使用するためコスト効率が良い
  - クラウド環境との親和性が高い

- **デメリット**：
  - ロードバランシングが必要
  - セッション管理やデータ共有の実装が複雑
  - ネットワーク遅延の考慮が必要

#### 垂直スケーリング（`Vertical Scaling`）

既存インスタンスのリソース（CPU、メモリ）を増減させる方法です。データベースなどのステートフルサービスに適していますが、ハードウェアの物理的限界があります。

- **メリット**：
  - アプリケーションの変更が最小限で済む
  - データベースなどのステートフルサービスに適している
  - ネットワークレイテンシの問題が少ない

- **デメリット**：
  - ハードウェアの物理的限界がある
  - スケーリング時に一時的なダウンタイムが発生することがある
  - コスト効率が悪くなりがち
  - 高可用性の実現が難しい

### オートスケーリング実装のワークフロー

効果的なオートスケーリングは以下の 4 つの主要なステップで実装されます。

#### 1. モニタリングシステム
   - CPU使用率：通常70-80%を超えるとスケールアウトのトリガーとなります
   - メモリ使用率：特にGPUメモリの消費量は重要な指標です
   - リクエスト待ち時間：レスポンスタイムの遅延はスケーリングのシグナルになります
   - キュー長：処理待ちリクエスト数の増加は負荷の増大を示します
   - スループット：単位時間あたりの処理リクエスト数も重要な指標です

#### 2. スケーリングポリシー
   - しきい値ベース：特定のメトリクスが閾値を超えたときにスケーリングを実行
   - スケジュールベース：予測可能なピーク時間に先行してスケーリングを実行
   - 予測スケーリング：機械学習を活用した需要予測に基づくプロアクティブなスケーリング
   - ステップスケーリング：負荷に応じて段階的にリソースを調整

#### 3. スケーリングアクション
   - スケールアウト：インスタンス追加によるキャパシティ増加
   - スケールイン：不要インスタンスの削減によるコスト最適化
   - クールダウン期間：連続したスケーリングアクションを防ぐための待機時間設定
   - ウォームアップ期間：新規インスタンスが完全に機能するまでの準備時間

#### 4. リソース調整
   - プロビジョニング：新しいインスタンスの起動と構成
   - デプロビジョニング：不要になったインスタンスの安全な削除
   - ヘルスチェック：新規インスタンスの正常性確認
   - ロードバランシング：トラフィックの適切な分散

### 生成 AI システムのスケーリングパターン

<Mermaid
  chart={`
flowchart TD
    subgraph api["API連携型"]
    direction LR
    A[アプリケーション] --> B[負荷分散] --> C1[APIゲートウェイ]
    C1 --> D1[外部AIプロバイダAPI]
    end

    subgraph self["セルフホスティング型"]
    direction LR
    A2[アプリケーション] --> B2[負荷分散] --> C2[推論サーバー群]
    C2 --> D2[GPUクラスタ]
    end

    api --> self
`}
/>

#### 1. API連携型
外部のAI APIサービス（OpenAI API、Claude API、Gemini API等）を利用するパターン。

- **特徴**：
  - 開発の容易さと迅速な導入が可能
  - インフラ管理の負担が少ない
  - API提供側のスケーリング機能に依存
  - 従量課金モデルにより初期コストが低い

- **適用シナリオ**：
  - スタートアップや小規模プロジェクト
  - プロトタイピングや概念実証（PoC）段階
  - 専門的なAIインフラ管理チームがない組織
  - 急速な市場投入が必要なケース

#### 2. セルフホスティング型
オープンソースモデルや独自モデルを自社インフラで稼働させるパターン。

- **特徴**：
  - 完全なカスタマイズとコントロールが可能
  - データプライバシーとセキュリティの確保
  - 大規模な利用時にコスト効率が向上
  - 専門的なインフラ知識とリソースが必要

- **適用シナリオ**：
  - 大規模な本番環境
  - 厳格なデータ規制がある業界
  - カスタムモデルの運用が必要なケース
  - 長期的なコスト最適化を重視する場合

### スケーリング戦略の意思決定フロー

<Mermaid
  chart={`
graph TD
  A[生成AIシステム] --> B{スケーリング必要？}
  B -- YES --> C[リソース消費パターンを把握]
  C --> D[スケーリング方式の選択]

  D --> E1[API連携型]
  D --> E2[セルフホスティング型]
  E2 --> F1[GPUリソース設計]
  E2 --> F2[オートスケーリング構築]
  F2 --> G1[モニタリング設定]
  F2 --> G2[スケーリングポリシー策定]
  F2 --> G3[スケーリングアクション定義]
  F2 --> G4[リソースプロビジョニング]
  G4 --> H[コスト・パフォーマンス最適化]
  B -- NO --> Z[固定構成でも可]
`}
/>

#### 意思決定の主要な観点

| 観点 | 内容 | 判断基準 |
|------|------|----------|
| 技術リソース | モデルの運用やインフラの知識があるか？ | 専門知識を持つエンジニアの有無 |
| コスト最適化 | 使用量に応じてコスト調整したいか？ | 月間リクエスト数と予算 |
| レイテンシ・制御性 | 応答時間やモデルバージョンなどを自前で管理したいか？ | 業務要件の厳格さ |
| セキュリティ要件 | データを外部 API に出せるか？ | 扱うデータの機密度 |
| スケーラビリティ | 大量アクセスに耐えうる設計が必要か？ | 予想されるピーク時のトラフィック量 |

#### スケーリング戦略選定表

| 条件 | API連携型 | セルフホスティング型 |
|------|----------|-----------------|
| 開発速度重視 | ✅ | |
| コスト予測性 | ✅ | |
| 高度なセキュリティ要件 | | ✅ |
| カスタムモデル必要 | | ✅ |
| 月間リクエスト数10万未満 | ✅ | |
| 月間リクエスト数100万以上 | | ✅ |
| 柔軟なスケーリング要件 | ✅ | |
| 低レイテンシ要件 | | ✅ |
| 技術チームの規模が小さい | ✅ | |
| データ主権の懸念 | | ✅ |

#### API連携型からセルフホスティング型への移行検討チェックリスト

- [ ] 月間 API コストが $10,000 (約150万円)を超える：この金額を超えると自社インフラの方がコスト効率が良くなる傾向があります
- [ ] レスポンス時間の短縮が必要：API レイテンシが業務要件を満たさなくなった場合
- [ ] 独自モデルの開発・デプロイが必要：特定ドメイン向けのカスタマイズや微調整が必要な場合
- [ ] 企業機密情報の取り扱いがある：高度なセキュリティや完全なデータ管理が求められる場合
- [ ] インフラ管理チームが整備されている：専門知識を持つエンジニアリングチームがスケーリング戦略を実装・管理できるか

### 主要なクラウドプロバイダーのオートスケーリングサービス

#### AWS オートスケーリング
- **EC2 Auto Scaling**：仮想マシンの需要に応じた自動スケーリング機能。詳細なスケーリングポリシーやスケジュールベースのスケーリングをサポート。複数のアベイラビリティゾーンにわたる高可用性構成も可能です。
- **SageMaker Endpoints**：機械学習モデルの推論に特化したスケーリング機能。トラフィックパターンに基づく自動スケーリングとインスタンスタイプの最適化が可能です。

#### Google Cloud Platform
- **GKE Cluster Autoscaler**：Kubernetes クラスターのノード数を需要に応じて自動調整。Pod 単位での細かいリソース管理と水平 Pod 自動スケーリング（HPA）をサポートしています。
- **Vertex AI**：AI モデルのスケーラブルなデプロイメントを実現。予測型スケーリングと GPU リソースの効率的な活用が可能です。

#### Microsoft Azure
- **Azure Kubernetes Service (AKS)**：マネージド Kubernetes サービスによる柔軟なスケーリング。KEDA（Kubernetes-based Event Driven Autoscaling）との統合によりイベント駆動型スケーリングも可能です。
- **Azure OpenAI Service**：マネージド AI 推論サービスで OpenAI モデルを容易にデプロイ。トークン単位の課金とスケーリングによりコスト効率に優れています。

### 生成 AI 関連のスケーリング動向（2025視点）

2025年現在、生成 AI システムのスケーリングにおける主要な技術トレンドは以下の通りです。

#### 1. vLLM によるスケーラブルな推論サーバ構築
ページドアテンションと KV-キャッシングによって、大規模言語モデル推論のスループットを最大 3 倍に向上させることで、
同一 GPU リソースでより多くのリクエストを処理できるようになりました。
この技術により、モデルのパフォーマンスを損なうことなく、大幅なコスト削減と処理能力向上が実現されています。

#### 2. NVIDIA Triton + Text Generation Inference
マルチ GPU デプロイメントにおいて、Transformer モデルのスケーリングを大幅に効率化。特に長いコンテキスト処理においてメモリ効率が向上しています。
テンソル並列処理とモデル並列処理の組み合わせにより、32k 以上のトークン長にも対応しながら高速な推論が可能になっています。

#### 3. 低レイテンシモデルと適応型スケーリング
最新の軽量モデル（Haiku、Gemma、Phi-3 等）を活用し、トラフィックパターンに応じてモデルサイズを動的に切り替える「適応型スケーリング」が主流になりつつあります。
負荷に応じて軽量モデルと大規模モデルを使い分けることで、コストとパフォーマンスの最適なバランスを実現しています。

### スケーリング検討のための実践的なステップ

1. **ユースケースの明確化**
   - 具体的な用途と目的を定義（チャットボット、ドキュメント生成、コード支援など）
   - 想定ユーザー数と同時アクセス数の予測
   - レスポンス時間要件の明確化（リアルタイム性の要求度）
   - ピーク時間帯とトラフィックパターンの分析

2. **プロトタイプによる計測**
   - 代表的なユースケースでの実際のリソース消費量測定
   - 平均処理時間とスループットのベンチマーク
   - GPUメモリ使用量の最大値と平均値の計測
   - 様々な入力長と複雑さでのパフォーマンス特性の把握

3. **段階的なスケーリング計画**
   - 初期デプロイメントには余裕を持たせたリソース割り当て
   - 実データに基づく継続的な最適化と調整
   - フェイルセーフ機構と過負荷対策の組み込み
   - 成長予測に基づく長期スケーリングロードマップの作成

### 生成 AI 特有の課題と対策

- **推論の不確実性**
  - タイムアウト設定：長時間実行されるリクエストの制限
  - 段階的な処理戦略：最大トークン数制限や処理の分割
  - 早期終了条件：特定条件での生成プロセスの安全な終了
  - フォールバックメカニズム：高負荷時の代替処理パス

- **ユーザー体験とレイテンシのバランス**
  - ストリーミングレスポンス：生成結果を逐次表示
  - 進捗表示の実装：長時間処理の視覚的フィードバック
  - クライアントサイドキャッシング：頻出クエリの応答時間短縮
  - 非同期処理オプション：バックグラウンド処理と通知

- **コスト管理**
  - 最大キャパシティ制限：予算超過防止の上限設定
  - コストアラート：閾値超過時の通知メカニズム
  - 使用状況モニタリング：詳細な利用統計と分析
  - 定期的な見直し：使用パターンに基づくリソース最適化

### まとめ

効果的なオートスケーリング戦略は、パフォーマンス、可用性、コスト効率のバランスを取りながら、変動する需要に対応できるシステムを実現します。
特に生成 AI システムでは、従来のウェブアプリケーションとは異なる特性を理解し、適切な指標とポリシーを選択することが重要です。

生成 AI の導入に際しては、技術的側面だけでなく、ビジネス要件や予算制約も考慮した総合的なスケーリング戦略が成功の鍵となります。
適切なモニタリング、段階的な実装アプローチ、そして継続的な最適化によって、コスト効率と高パフォーマンスを両立させた AI システムの構築が可能になります。
