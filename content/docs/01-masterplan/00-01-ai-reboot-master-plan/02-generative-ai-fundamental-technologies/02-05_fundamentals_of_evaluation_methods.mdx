---
title: 評価手法の基礎
description: Fundamentals of Evaluation Methods
icon: ChartLine
---

import { Mermaid } from "@/components/mdx/mermaid";

## 評価手法の基礎: 出力品質と適合性の評価指標

### 🔑 エグゼクティブサマリー

本ドキュメントでは、大規模言語モデル（LLM）を含むシステム出力の品質と適合性を評価するための基本的な手法と指標について説明します。
適切な評価指標の選択と測定方法を理解することで、LLM の性能を客観的に把握し、改善につなげることが可能になります。
特に定量的および定性的評価手法の違いや、LLM 特有の評価指標、ビジネス要件との整合性の測定方法について詳しく解説します。

### はじめに

#### 本ドキュメントの想定読者

- LLM や生成 AI システムの評価を担当するエンジニアやアナリスト
- AI モデルの品質管理プロセスの設計者
- 生成 AI プロダクトのマネージャーや意思決定者

#### 対象とするシステム規模

本ドキュメントの内容は、小規模な AI アプリケーションから大規模な言語モデルまで、幅広い生成 AI システムに適用可能です。
ただし、実際の評価指標の選択と測定方法は、モデルの特性や目的に応じて調整する必要があります。

### 評価の目的

LLM を含む AI システム出力の評価を行う主な目的は以下の通りです。

- モデルの現在の性能レベルの把握
- 改善が必要な領域の特定
- 設計目標や要件との適合性の検証
- 継続的な品質管理とモニタリング
- 意思決定のための客観的なデータの提供

### 評価指標の種類

評価指標は大きく分けて以下の2つのカテゴリに分類できます。

#### 1. 定量的評価指標

定量的評価指標は、数値で測定可能な客観的な指標です。主な定量的評価指標は以下の通りです。

- **精度 (Accuracy)**: 正確に処理された出力の割合
- **適合率 (Precision)**: 陽性と予測したケースのうち、実際に陽性だったケースの割合
- **再現率 (Recall)**: 実際の陽性ケースのうち、正しく陽性と予測できたケースの割合
- **F1スコア (F1 Score)**: 適合率と再現率の調和平均
- **パープレキシティ (Perplexity)**: モデルが次のトークンを予測する難しさを測定する指標
- **BLEU/ROUGE/METEOR**: 機械翻訳や要約タスクでの出力品質を評価する指標
- **応答時間 (Response Time)**: システムが処理を完了するまでの時間
- **スループット (Throughput)**: 単位時間あたりの処理量

##### 定量的評価指標の利用の適切性

各指標の適切な利用場面と限界を理解することは重要です：

| 指標 | 適した用途 | 不向きな用途 | 利用上の留意点 |
|------|-----------|------------|--------------|
| **精度 (Accuracy)** | 分類タスク、事実的QA | 不均衡データセット、創造的タスク | クラス不均衡がある場合は適合率・再現率と併用すべき |
| **F1スコア** | 不均衡データセット、分類タスク | 創造的なテキスト生成 | 適合率と再現率のどちらを重視するかでβ値を調整可能 |
| **パープレキシティ** | 言語モデルの学習評価、モデル選定 | 生成文の品質評価、実用的な性能測定 | 低いほど良いが、実際のタスクパフォーマンスとは相関しないことも |
| **BLEU** | 機械翻訳、定型的な生成タスク | 創造的な文章生成、会話型応答 | n-gramの一致のみを見るため、意味的な正確さは評価できない |
| **ROUGE** | 要約タスク、情報抽出 | 探索的な回答、創造的な生成 | リファレンス要約への依存度が高く、多様な正解がある場合は不適切 |
| **BERTスコア** | 意味的類似性の評価、複雑な生成タスク | 単純な分類タスク、計算効率が重要な場面 | 計算コストが高く、解釈が直感的でない場合がある |

#### 2. 定性的評価指標

定性的評価指標は、主観的な判断や質的な特性に基づく指標です。主な定性的評価指標は以下の通りです。

- **使用性 (Usability)**: システムの使いやすさやユーザー体験
- **関連性 (Relevance)**: 出力結果がユーザーのニーズや意図に関連している程度
- **明瞭性 (Clarity)**: 出力内容の明確さと理解のしやすさ
- **一貫性 (Consistency)**: 類似の入力に対して一貫した出力を提供する能力
- **信頼性 (Reliability)**: システム出力の信頼度や安定性

##### 定性的評価指標の利用の適切性

定性的評価指標も用途に応じて選択する必要があります：

| 指標 | 適した用途 | 不向きな用途 | 利用上の留意点 |
|------|-----------|------------|--------------|
| **使用性 (Usability)** | エンドユーザー向けアプリケーション、インタフェース評価 | 基盤モデルの性能評価、バックエンド処理 | SUS（System Usability Scale）などの標準化されたフレームワークの使用を検討 |
| **関連性 (Relevance)** | 検索システム、推薦システム、質問応答 | 特定のタスク指向のシステム、創造的生成 | 評価者間でのばらつきが大きいため、複数評価者と明確な基準が必要 |
| **明瞭性 (Clarity)** | 説明生成、教育コンテンツ、技術文書 | 創造的文章、専門家向けの高度な内容 | 対象オーディエンスのレベルに合わせた評価基準の設定が重要 |
| **一貫性 (Consistency)** | 長文生成、ストーリーテリング、複数回のやり取り | 探索的な回答、創造性重視のタスク | 文脈の長さや範囲を明確に定義し、評価の一貫性を確保 |
| **信頼性 (Reliability)** | ミッションクリティカルなアプリケーション、医療・法務分野 | 実験的なプロトタイプ、創造的コンテンツ生成 | 信頼性の要素（安定性、精度、一貫性）の優先順位を明確にする |

### 出力品質 vs 適合性の比較

出力品質と適合性は LLM 評価において異なる側面を持っています。以下の表は両者の主な違いを示しています。

| 観点 | 出力品質 | 適合性 |
|------|----------|--------|
| 主な対象 | モデル出力自体 | システム要件やユーザーニーズとの整合性 |
| 評価軸 | 正確性、明瞭性、一貫性など | 完全性、効率性、信頼性、互換性など |
| 評価タイミング | 推論直後 | システム全体設計やデプロイ後 |
| 手法の例 | BLEU, F1, ユーザーレビュー | ユースケーステスト、NFR テスト |

出力品質と適合性の違いを視覚的に表現すると以下のようになります：

<Mermaid chart={`
flowchart LR
    subgraph 出力品質
        Q1[正確性]
        Q2[明瞭性]
        Q3[一貫性]
    end

    subgraph 適合性
        C1[要件との整合性]
        C2[性能効率性]
        C3[信頼性]
    end

    Q1 --> Eval[モデル出力評価]
    Q2 --> Eval
    Q3 --> Eval

    C1 --> Fit[システム全体評価]
    C2 --> Fit
    C3 --> Fit

    style 出力品質 fill:#90EE90,stroke:#006400,color:#000
    style 適合性 fill:#FFD700,stroke:#B8860B,color:#000
    style Eval fill:#87CEFA,stroke:#0047AB,color:#000
    style Fit fill:#FF6347,stroke:#8B0000,color:#000
`} />

### LLM 特有の評価カテゴリ

LLM の評価には、一般的なシステム評価とは異なる特有のカテゴリがあります。

#### 事実性 (Factuality)

- **事実的正確さ**: 生成されたコンテンツが事実と一致しているか
- **情報源への忠実性**: 参照情報源の内容を正確に反映しているか
- **事実検証可能性**: 生成された主張が検証可能か
- **実装方法**: 外部ナレッジベース（Wikipedia、信頼できる情報源）とのクロスチェックAPI、参照リンク追跡機能

<Callout type="info" title="幻覚との違いについて">
事実性は「生成コンテンツが実際の事実と一致する度合い」を評価します。既知の事実に対する忠実度を測定します。
</Callout>

#### 有害性 (Harmfulness)

- **有害コンテンツの回避**: 差別的、暴力的、または不適切なコンテンツを生成しないか
- **バイアスの検出**: 社会的バイアスや偏見を含んでいないか
- **安全性評価**: 悪用可能性のあるコンテンツの生成回避能力
- **実装方法**: 有害性分類器、プロンプトパターン検出システム、多層フィルタリング

#### 幻覚 (Hallucination)

- **存在しない情報の創作**: 実際には存在しない情報を事実として提示していないか
- **情報の誤った関連付け**: 正確な情報を誤った文脈で組み合わせていないか
- **不確実性の表現**: 確信がない場合に適切に不確実性を伝えているか
- **実装方法**: 文書抽出根拠検証、不確かさスコアリング、ソース追跡メカニズム

<Callout type="info" title="事実性との違いについて">
幻覚は「存在しない情報を事実として提示する現象」を評価します。

事実性が「実際の事実への忠実さ」を測るのに対し、幻覚は「虚構を事実と偽る傾向」を測定します。両者は表裏一体の関係にありますが、焦点が異なります。
</Callout>

#### 指示忠実性 (Instruction Following)

- **指示理解度**: ユーザーの指示を正確に理解しているか
- **タスク遂行能力**: 指示に基づいて適切にタスクを実行できるか
- **境界認識**: モデルの能力の限界を認識し、適切に対応しているか
- **実装方法**: 指示テンプレートを用いた自動検証スクリプト、タスク完了率測定ツール、遵守度スコアリング

#### LLM特有の評価指標の利用文脈

LLM特有の評価カテゴリについても、適切な利用場面と限界を理解することが重要です：

| 評価カテゴリ | 適した場面 | 不向きな場面 | 実装上の考慮事項 |
|------------|-----------|------------|----------------|
| **事実性 (Factuality)** | 知識集約型タスク、教育コンテンツ、情報提供 | 創造的ライティング、フィクション生成 | 参照ソースの質と多様性、ドメイン固有の知識検証が重要 |
| **有害性 (Harmfulness)** | 公開向けアプリケーション、子供向けサービス | 内部開発プロトタイプ、専門家限定システム | 文化的文脈の違いを考慮した多角的評価が必要 |
| **幻覚 (Hallucination)** | 事実に基づく情報提供、学術・医療・法務用途 | ブレインストーミング、創造的アイデア生成 | RAGの実装と生成内容の検証メカニズムの統合が有効 |
| **指示忠実性 (Instruction Following)** | ツール利用、特定タスク実行、専門業務支援 | オープンエンドな会話、探索的対話 | 明確な指示とタスク固有のガイドラインが評価の前提 |

### 出力品質の評価手法

出力品質を評価するための主な手法は以下の通りです。

#### ベンチマークテスト

- 標準的なテストデータセットを使用して性能を測定
- GLUE、SuperGLUE、MMLU などの LLM 用ベンチマーク
- 業界標準や競合製品との比較が可能
- 再現性が高く、客観的な評価が可能

#### A/B テスト

- 異なるバージョンのシステムを比較評価
- ユーザーをランダムに分けて異なるバージョンを提供
- 実際のユーザー環境での性能差を測定
- バイアス軽減のためにブラインド評価を導入

#### ユーザーベース評価

- ユーザーに直接評価を依頼するアプローチ
- 個別評価：各出力に対して独立した評価（例：5段階評価）
- ペアワイズ評価：2つの出力を直接比較し、どちらが優れているかを判断
- ランキングベース評価：複数の出力に順位をつける

#### ユーザーフィードバック

- アンケートや評価フォームによる直接的なフィードバック収集
- インタビューやフォーカスグループによる詳細な意見収集
- 実際のユーザー体験に基づく評価が可能
- 質的データと量的データの両方を収集するハイブリッドアプローチ

#### 自動評価スクリプト

- プログラムによる自動的な品質チェック
- 大量のテストケースを効率的に処理
- 継続的な監視と評価が可能
- 定量的指標のバッチ処理と可視化を自動化

#### プロンプトベースの評価手法

- **チェーン・オブ・ソート評価**: 複雑な推論過程を段階的に評価
- **自己評価と自己改善**: モデル自身によるアウトプットの評価と改善
- **レッドチーミング**: 脆弱性やエッジケースを探るための系統的テスト
- **BERTスコア/Semantic Similarity**: 意味的類似性に基づく評価

### 適合性の評価指標

システムの出力が要件や期待に適合しているかを評価するための指標は以下の通りです。

#### 機能的適合性指標

- **機能完全性 (Functional Completeness)**: 仕様で定義されたすべての機能が実装されている程度
- **機能正確性 (Functional Correctness)**: 実装された機能が仕様通りに正確に動作する程度
- **機能適切性 (Functional Appropriateness)**: 実装された機能がユーザーのタスクや目標に適している程度

#### 非機能的適合性指標

- **性能効率性 (Performance Efficiency)**: リソース使用量と処理能力のバランス
- **互換性 (Compatibility)**: 他のシステムやコンポーネントとの連携能力
- **使いやすさ (Usability)**: ユーザーインターフェースの使いやすさと学習のしやすさ
- **信頼性 (Reliability)**: システムの安定性と回復能力
- **セキュリティ (Security)**: データやシステムの保護能力

### 評価指標の選定フロー

LLM の評価指標を選定する際の基本的なフローチャートを以下に示します。このフローは、評価の目的や状況に応じて適切な指標を選ぶための指針となります。

<Mermaid chart={`
graph TD
    A[評価開始] --> B{評価の主な目的は?}
    B -->|モデル性能の測定| C[定量的評価]
    B -->|ユーザー満足度の測定| D[定性的評価]
    B -->|システム要件適合の確認| E[適合性評価]

    C --> F{タスクの種類は?}
    F -->|自然言語生成| G[BLEU/ROUGE/パープレキシティ]
    F -->|質問応答| H[精度/F1スコア/正解率]
    F -->|分類| I[適合率/再現率/F1スコア]

    D --> J{評価したい側面は?}
    J -->|使いやすさ| K[ユーザビリティテスト/SUS]
    J -->|関連性| L[人間評価/関連性スコア]
    J -->|明瞭性| M[読みやすさ指標/人間評価]

    E --> N{評価したい適合性は?}
    N -->|機能的適合性| O[機能テスト/カバレッジ分析]
    N -->|非機能的適合性| P[性能テスト/信頼性テスト]

    G & H & I --> Q[自動評価スクリプト実行]
    K & L & M --> R[ユーザー調査/専門家レビュー]
    O & P --> S[要件トレーサビリティ分析]

    Q & R & S --> T[結果分析]
    T --> U[改善点の特定]
    U --> V[評価終了]

    style A fill:#87CEFA,stroke:#0047AB,color:#000
    style B fill:#90EE90,stroke:#006400,color:#000
    style C fill:#FFD700,stroke:#B8860B,color:#000
    style D fill:#FFD700,stroke:#B8860B,color:#000
    style E fill:#FFD700,stroke:#B8860B,color:#000
    style V fill:#FF6347,stroke:#8B0000,color:#000
`} />

### 評価指標選定のチェックリスト

以下のチェックリストは、適切な評価指標を選択する際のガイドとなります。

1. **評価の目的を明確化する**
   - [ ] モデルの性能改善のためか
   - [ ] ユーザー体験の向上のためか
   - [ ] システム要件への適合性確認のためか

2. **評価対象を特定する**
   - [ ] 生成テキストの品質（流暢さ、一貫性など）
   - [ ] 事実的正確性
   - [ ] 回答の関連性と有用性
   - [ ] 有害コンテンツの回避能力

3. **利用可能なリソースを確認する**
   - [ ] 自動評価のためのツールとスクリプト
   - [ ] 人間評価者の可用性
   - [ ] 評価に利用できる時間と予算

4. **定量的指標と定性的指標のバランスを取る**
   - [ ] 定量的測定のための指標（BLEU、適合率など）
   - [ ] 定性的評価のための手法（ユーザーフィードバック、専門家レビューなど）

5. **業界・領域特有の要件を考慮する**
   - [ ] 規制要件や業界標準
   - [ ] ドメイン固有の品質基準
   - [ ] 特定のユースケースに関連する指標

### 評価目的別の指標マッピング表

評価の目的によって最適な指標は異なります。以下の表は、評価目的に応じた推奨指標と手法の例を示しています。

| 評価目的 | 推奨される指標 | 手法例 |
|---------|---------------|--------|
| モデル出力の正確性 | F1, BLEU, ROUGE, 適合率/再現率 | ベンチマーク, 自動評価 |
| ユーザー満足度 | Usability, Relevance, CSAT | ユーザーフィードバック, A/B テスト |
| セーフティ確認 | Harmfulness, Hallucination rate | Red teaming, 人的評価, 安全性監査 |
| 性能劣化検知 | Response Time, Throughput, エラー率 | 継続的評価, モニタリング |
| 事実的正確性 | Factuality score, BERTスコア | 事実検証, RAG評価 |
| 指示忠実性 | Instruction following rate | 人間評価, タスク完了率 |
| コード生成品質 | 構文正確性, 実行成功率, 効率性 | 単体テスト, コードレビュー |
| 知識更新度 | 最新情報の正確性, 更新内容の反映率 | 時系列テスト, 新情報評価 |

### 業界別評価アプローチ

異なる業界や用途に応じて、評価の重点は大きく異なります。以下に主要な業界における評価の優先事項を示します。

| 業界/用途 | 重視すべき評価指標 | 特徴的な評価手法 | 特有の考慮事項 |
|-----------|-------------------|-----------------|--------------|
| **医療** | 事実性（95%+）、有害性回避 | 専門家監査、根拠検証 | 医学的根拠の正確な引用、診断支援への制限 |
| **法務** | 正確性、最新性、関連法令の網羅性 | 法律専門家によるレビュー、判例参照の正確性 | 法的責任、管轄による法律の違い |
| **教育** | 教育的価値、年齢適合性、説明の明瞭さ | 教育効果測定、学習者フィードバック | 学習レベルに合わせた表現、誤概念の回避 |
| **金融** | 計算精度、リスク説明の完全性 | コンプライアンス監査、シナリオテスト | 規制遵守、責任ある金融アドバイス |
| **カスタマーサポート** | 応答速度、解決率、顧客満足度 | CSAT、NPS、解決時間測定 | 顧客体験、エスカレーションの適切さ |
| **コンテンツ作成** | 創造性、オリジナリティ、一貫性 | 人間評価者による品質評価、プラグイアリズム検出 | 著作権問題、ブランドボイスの一貫性 |

### 評価事例：複数の実運用ユースケース

#### 事例1：チャットサポート用 LLM の評価

カスタマーサポート向けに微調整された LLM を評価した際の例です：

初期評価では、**指示忠実性**スコアが高く（90%）、迅速に返答できるものの、**幻覚率**が高い（15%）ことが判明しました。
実際の顧客対応では、製品仕様について誤った情報を自信を持って提供するケースが複数確認されました。

**改善アプローチ**:
1. BERTスコアを使用して、回答と公式ドキュメントの意味的一致度を測定
2. 人間のレビュワーによる事実性評価を追加
3. 幻覚検出に特化した自動チェックツールを開発

**結果**:
幻覚率を 15% から 3% に低減し、顧客満足度スコアが 78% から 92% に向上しました。
このケースは単一の評価指標だけでなく、複合的な評価アプローチの重要性を示しています。

#### 事例2：医療FAQボットの評価

**背景**：患者向け医療情報FAQボットを開発し、様々な健康関連の質問に回答。

**主要評価指標**：
- **事実性スコア**（95%）：医学的に正確な情報提供
- **説明の明瞭さ**（90%）：医学用語の適切な説明
- **責任ある限定**（100%）：医療アドバイスではなく情報提供にとどめる

**評価プロセス**：
1. 医学専門家パネルによる回答の審査
2. 標準医療ガイドラインとの整合性確認
3. ユーザー理解度テスト（一般の人が説明を理解できるか）

**改善点の特定**：
- 特定の症状に関する回答で幻覚が発生（事実と異なる治療法の提案）
- 改善策：医学ガイドラインのRAG実装、症状関連の質問に対する自動免責事項追加

#### 事例3：法的文書要約モデルの評価

**背景**：法律文書を要約し、重要ポイントを抽出するLLMベースのツール。

**主要評価指標**：
- **法的重要事項の抽出精度**（93%）：重要な法的条項の見落としがないか
- **ROUGE-L**（78%）：専門家による要約との一致度
- **ユーザー満足度**（85%）：法律実務家による実用性評価

**評価プロセス**：
1. 法律専門家による重要条項抽出比較評価
2. 見落とし（False Negative）率の特定と重み付け
3. 実務環境での使用テスト

**改善点の特定**：
- 契約書の特定条項（準拠法、仲裁条項）の重要性を過小評価
- 改善策：法的重要度に基づく微調整と特定条項検出機能の追加

### 評価における課題と対策

評価プロセスで直面する一般的な課題と、その対策は以下の通りです。

#### 一般的な課題

- **バイアス**: 評価者や評価方法によるバイアスの混入
- **不完全なデータ**: 評価に必要なデータの不足や偏り
- **コンテキストの欠如**: ユーザーのコンテキストや意図の理解不足
- **過剰最適化**: 特定の指標に対する過剰な最適化
- **評価指標の不一致**: 異なる評価指標間の矛盾や不一致

#### LLM特有の課題

- **評価データの多様性**: 様々な言語や文化的背景を考慮した評価の難しさ
- **黒箱性**: モデルの内部動作の不透明さによる評価の難しさ
- **主観性**: 出力の良し悪しが主観的判断に依存する場合がある
- **ベンチマークへの過適合**: 特定のベンチマークに特化した最適化

#### 対策

- **多角的評価**: 複数の指標や方法を組み合わせた評価
- **継続的評価**: 一時的ではなく継続的な評価プロセスの実施
- **ユーザー中心設計**: 実際のユーザーニーズに基づいた評価基準の設定
- **バランスの取れた指標**: 相補的な指標のセットを使用する
- **人間とAIの協調評価**: 人間の判断とAIによる自動評価の組み合わせ

### 学習パラダイムに関連した評価指標

LLM の学習パラダイムに応じた評価指標も重要です。

#### 事前学習モデルの評価

- **言語理解能力**: 文脈や意味の理解度
- **知識表現**: 事前学習で獲得した知識の正確さと範囲
- **汎化能力**: 未見のデータやタスクへの適応力

#### 微調整（ファインチューニング）後の評価

- **タスク特化性能**: 特定のタスクでの性能向上度
- **オーバーフィッティング**: 訓練データへの過剰適合の有無
- **転移学習効率**: 学習した能力が他のタスクにも転移する程度

### 評価プロセスのステップ

効果的な評価プロセスを実施するための基本的なステップは以下の通りです。

1. **評価目標の設定**: 何を評価するのか、何のために評価するのかを明確にする
2. **評価指標の選択**: 目標に適した定量的・定性的指標を選ぶ
3. **評価方法の設計**: データ収集方法やテスト環境を設計する
4. **データ収集**: 選択した方法でデータを収集する
5. **分析と解釈**: 収集したデータを分析し、結果を解釈する
6. **改善策の特定**: 評価結果に基づいて改善すべき領域を特定する
7. **改善実施とフォローアップ**: 改善策を実施し、再評価を行う

### 評価結果の活用方法

評価結果を効果的に活用するための方法は以下の通りです。

- **優先順位付け**: 改善すべき領域の優先順位付け
- **意思決定支援**: リリース判断や投資判断のための客観的データとして活用
- **トレンド分析**: 時間経過による変化の把握と長期的な改善計画の策定
- **ステークホルダーコミュニケーション**: 開発状況や品質レベルの共有
- **モデル選択**: 複数のモデルバージョンから最適なものを選択するための基準

### 評価システムの構成図

<Mermaid chart={`
graph TD
    A[LLM評価システム] --> B[定量的評価 数値化された指標]
    A --> C[定性的評価 主観的判断]
    A --> D[LLM特有の評価]
    B --> E[精度/適合率/再現率]
    B --> F[パープレキシティ/BLEU/ROUGE]
    C --> G[使用性/関連性]
    C --> H[明瞭性/一貫性]
    D --> I[事実性]
    D --> J[有害性]
    D --> K[幻覚]
    D --> L[指示忠実性]
    E --> M[自動テストスイート]
    F --> M
    G --> N[ユーザーフィードバック]
    H --> O[専門家レビュー]
    I --> P[事実検証ツール]
    J --> Q[有害性検出システム]
    K --> R[幻覚評価フレームワーク]
    L --> S[指示追従評価]
    M --> T[評価ダッシュボード]
    N --> T
    O --> T
    P --> T
    Q --> T
    R --> T
    S --> T
    style A fill:#87CEFA,stroke:#0047AB,color:#000
    style B fill:#90EE90,stroke:#006400,color:#000
    style C fill:#FFD700,stroke:#B8860B,color:#000
    style D fill:#FF6347,stroke:#8B0000,color:#000
    style T fill:#BA55D3,stroke:#4B0082,color:#000
`} />

### まとめ

LLM の出力品質と適合性の評価は、モデル開発と改善の重要な側面です。
適切な評価指標を選択し、体系的な評価プロセスを実施することで、モデルの現状を客観的に把握し、効果的な改善につなげることができます。

定量的評価と定性的評価のバランスを取り、LLM 特有の評価カテゴリを考慮しながら、ユーザーのニーズと期待に合致したシステムを構築することが重要です。
また、評価は一度きりのプロセスではなく、継続的なフィードバックループの一部として位置づけるべきです。

### 用語解説

| 用語 | 説明 |
|------|------|
| 精度 (Accuracy) | 全予測のうち、正確に予測された割合 |
| 適合率 (Precision) | 陽性と予測したケースのうち、実際に陽性だったケースの割合 |
| 再現率 (Recall) | 実際の陽性ケースのうち、正しく陽性と予測できたケースの割合 |
| F1スコア | 適合率と再現率の調和平均 (2 * 精度 * 再現率) / (精度 + 再現率) |
| パープレキシティ | モデルが次のトークンを予測する難しさを測定する指標。低いほど良い |
| BLEU (Bilingual Evaluation Understudy) | 機械翻訳における n-gram の一致率指標。参照訳と生成訳の類似度を測定 |
| ROUGE (Recall-Oriented Understudy for Gisting Evaluation) | 要約評価で使われる、n-gram の重なり率。参照要約と生成要約の一致度を測定 |
| METEOR | 機械翻訳評価指標の一つ。単語の同義語や語形変化も考慮した柔軟な一致度評価 |
| BERTスコア | BERT モデルを使用して文の意味的類似性を評価する指標 |
| チェーン・オブ・ソート | 複雑な推論を段階的に分解して評価する手法 |
| 幻覚 (Hallucination) | LLM が実際には存在しない情報を事実として提示する現象 |
| A/B テスト | 2つのバージョンを比較するための実験的手法 |
| ベンチマーク | 性能比較のための標準的な参照点や測定基準 |
| 機能的適合性 | システムが指定された機能要件を満たす程度 |
| 非機能的適合性 | 性能、セキュリティなどの非機能要件を満たす程度 |
| レッドチーミング | システムの脆弱性や問題点を見つけるために意図的に挑戦的なテストを行う手法 |## 評価手法の基礎: 出力品質と適合性の評価指標
