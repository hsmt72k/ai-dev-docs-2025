---
title: 2. 生成 AI 基盤技術
description: Generative AI Fundamental Technologies
icon: Atom
---

### 2. 生成 AI 基盤技術

#### 2.0 AI の歴史と発展

- **初期のAIの誕生と基礎理論 (1950 〜 1960年代)**: AIの初期の概念と理論。
- **AIの冬とその原因 (1970 〜 1990年代)**: AI の停滞期、計算資源の不足や理論的限界
- **機械学習と深層学習の復活 (2000年代以降)**: 計算能力の向上と大規模データによる変化
- **大規模データと Transformer アーキテクチャの登場 (2010年代)**: Transformer モデルの登場とその進化
- **生成 AI の台頭**: 大規模言語モデル（LLM）の登場とその応用領域

#### 2.1 機械学習とディープラーニングの基礎

- **機械学習の基本概念**: 教師あり学習、教師なし学習、強化学習
- **ディープラーニングの基本概念**: ニューラルネットワーク、バックプロパゲーション
- **CNN (畳み込みニューラルネットワーク)**: 画像処理や特徴抽出のためのアーキテクチャ
- **RNN (リカレントニューラルネットワーク)**: 時系列データ処理のためのアーキテクチャ
- **GAN (生成的敵対ネットワーク)**: 画像生成やデータ生成のための技術

#### 2.2 LLM 基礎知識（理論理解・構造）

- [**LLM の基本原理**](./02-generative-ai-fundamental-technologies/02-01_basic_principles_of_llm): トークン化、コンテキストウィンドウ、推論の仕組み
- [**Transformer の全体構造**](./02-generative-ai-fundamental-technologies/02-02_overall_structure_of_transformer): モジュール構成と処理フロー
- [**Attention の内部機構**](./02-generative-ai-fundamental-technologies/02-03_internal_mechanism_of_attention): 各種 Attention と位置情報の扱い
- [**学習パラダイムの基礎**](./02-generative-ai-fundamental-technologies/02-04_foundations_of_learning_paradigms): 事前学習と微調整の違いと役割
- [**評価手法の基礎**](./02-generative-ai-fundamental-technologies/02-05_fundamentals_of_evaluation_methods): 出力品質と適合性の評価指標

#### 2.3 LLM 応用・実践技術（活用・改善）

- **プロンプトエンジニアリング**: 効果的な指示設計、フォーマット制御、出力制御
- **RAG（検索拡張生成）**: ベクトル検索、埋め込み生成、外部知識との結合
- **ファインチューニング技術と PEFT の実践**: LoRA、Adapter、Prefix Tuning などの軽量手法
- **モデル AB テストとマルチアーム設計**: フォールバック、実験設計、多モデル切り替え戦略
- **モデルバージョン管理とデプロイ**: カナリアリリース、ブルー/グリーンデプロイ、運用戦略

#### 2.4 分散モデル実行と最適化基盤（ハードウェア・インフラ視点）

- **ローカルモデル運用**: ローカル環境でのモデル推論実現のアーキテクチャ設計と最適化手法
- **エッジ AI 実装**: オンデバイス推論、モデル圧縮、オフライン処理
- **ハイブリッドデプロイメント**: ローカルモデルとクラウドモデルの使い分け
- **推論アクセラレーション**: バッチ処理、量子化、プルーニング、NPU/GPU活用、キャッシュ戦略
- **モデルコントロールプレーン (MCP)**: モデルルーティング、負荷分散、自動切り替え
